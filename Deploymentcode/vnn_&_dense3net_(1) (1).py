# -*- coding: utf-8 -*-
"""VNN_&_Dense3Net (1).ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1jT31Xp1T_W1OkbvdoOvaL5L9xsceAGQM
"""

!pip install opendatasets

"""**IMPORTING LIBRARIES**"""

from keras.models import Sequential
from keras.preprocessing.image import ImageDataGenerator
from keras.applications import DenseNet121
from keras.applications.vgg16 import VGG16
from keras.layers import Dense, Dropout, Activation, Input, Flatten
from keras.layers import Conv2D, MaxPooling2D, GlobalMaxPooling2D,BatchNormalization, GlobalAveragePooling2D
from keras.optimizers import Adam
from keras import regularizers
import tensorflow as tf


import pandas as pd
import os
import numpy as np
import matplotlib.pyplot as plt
import cv2

import warnings
warnings.filterwarnings('ignore')

from sklearn.metrics import confusion_matrix, accuracy_score, classification_report
from mlxtend.plotting import plot_confusion_matrix

"""**DOWNLOADING DATASE**"""

import opendatasets as od
od.download("https://www.kaggle.com/datasets/andrewmvd/pediatric-pneumonia-chest-xray/data")

train_path = "../content/pediatric-pneumonia-chest-xray/Pediatric Chest X-ray Pneumonia/train"
test_path = "../content/pediatric-pneumonia-chest-xray/Pediatric Chest X-ray Pneumonia/test"

normal_images = [img for img in os.listdir(f'{train_path}/NORMAL')]
pneumonia_images = [img for img in os.listdir(f'{train_path}/PNEUMONIA')]

normal_select = np.random.choice(normal_images, 5, replace=False)
pneumonia_select = np.random.choice(pneumonia_images, 5, replace=False)

"""**Plotting the Images to understand difference between Noraml X-ray Images and X-Rays with Pneumonia**"""

#Plot the selected images
from tensorflow.keras.preprocessing import image
fig = plt.figure(figsize=(8,5))
for i in range(10):
    if i<5:
        fpath = f'{train_path}/NORMAL/{normal_select[i]}'
        label = 'NORMAL'
    else:
        fpath = f'{train_path}/PNEUMONIA/{pneumonia_select[i-5]}'
        label = 'PNEUMONIA'
    ax = fig.add_subplot(2,5,i+1)

    im = image.load_img(fpath)
    plt.imshow(im)
    plt.title(label)
    plt.axis('off')
plt.show()

"""DATA MODELLING & PREPROCESSING"""

train_datagen = ImageDataGenerator(
        rescale=1 / 255.0,
        rotation_range=20,
        zoom_range=0.05,
        width_shift_range=0.05,
        height_shift_range=0.05,
        shear_range=0.05,
        horizontal_flip=True,
        fill_mode="nearest",
        validation_split=0.20)

test_datagen = ImageDataGenerator(rescale=1 / 255.0)

batch_size = 8
train_generator = train_datagen.flow_from_directory(
    directory=train_path,
    target_size=(180,180),
    color_mode="rgb",
    batch_size=batch_size,
    class_mode="categorical",
    subset='training',
    shuffle=True,
    seed=42
)
valid_generator = train_datagen.flow_from_directory(
    directory=train_path,
    target_size=(180,180),
    color_mode="rgb",
    batch_size=batch_size,
    class_mode="categorical",
    subset='validation',
    shuffle=True,
    seed=42
)
test_generator = test_datagen.flow_from_directory(
    directory=test_path,
    target_size=(180,180),
    color_mode="rgb",
    batch_size=1,
    class_mode=None,
    shuffle=False,
    seed=42
)

"""**Function for seperating the Target Data**"""

def Target_Data_Seperation(folder_path, target_path):
    label = []
    for path, tag in target_path:
        for filename in os.listdir(folder_path + path):
            img = cv2.imread(os.path.join(folder_path, path, filename)) # second param: 0 is b&w picture
            if img is not None:
                label.append(tag)
    return np.array(label)

"""VGG MODEL CREATION"""

vgg_model = Sequential()

vgg_pretrained_model=VGG16(include_top=False,input_shape=(180,180,3),pooling='avg',classes=2,weights='imagenet')

for layer in vgg_pretrained_model.layers:
        layer.trainable=False

vgg_model.add(vgg_pretrained_model)
vgg_model.add(Flatten())
vgg_model.add(Dense(512, activation='relu'))
vgg_model.add(Dense(2, activation='sigmoid'))

vgg_model.summary()

"""Training the VGG model"""

vgg_model.compile(optimizer=Adam(learning_rate=0.001),loss='binary_crossentropy',metrics=["accuracy","AUC","Precision","Recall"])

vgg_model_history = vgg_model.fit(train_generator, validation_data=train_generator, epochs=3)

plt.figure(1, figsize = (12,6))

plt.subplot(221)
plt.plot(vgg_model_history.history['accuracy'])
plt.plot(vgg_model_history.history['val_accuracy'])
plt.title('model accuracy')
plt.ylabel('accuracy')
plt.xlabel('epoch')
plt.legend(['train', 'valid'])

plt.subplot(222)
plt.plot(vgg_model_history.history['loss'])
plt.plot(vgg_model_history.history['val_loss'])
plt.title('model loss')
plt.ylabel('loss')
plt.xlabel('epoch')
plt.legend(['train', 'valid'])

plt.show()

test_generator.reset()

pred = vgg_model.predict(test_generator, steps = len(test_generator), verbose = 2)

predicted_class_indices = np.argmax(pred, axis = 1)



base_dir= "../content/pediatric-pneumonia-chest-xray/Pediatric Chest X-ray Pneumonia/"
y_test = Target_Data_Seperation(base_dir, target_path=[("test/NORMAL/", 0,), ("test/PNEUMONIA/", 1,)])

"""**Evaluation Metrics**"""

print(plot_confusion_matrix(confusion_matrix(y_test, predicted_class_indices), figsize=(5,5)))
print(accuracy_score(y_test, predicted_class_indices))
print(classification_report(y_test, predicted_class_indices))
plt.show()

"""**DenseNet121 Implementation**"""

denset_net_pretrained_model = DenseNet121(weights="imagenet", include_top=False, input_tensor=Input(shape=(180, 180, 3)))
# construct the head of the model that will be placed on top of the
# the base model
dense_net_model = Sequential()
dense_net_model.add(denset_net_pretrained_model)
dense_net_model.add(GlobalAveragePooling2D())
dense_net_model.add(Flatten())
dense_net_model.add(Dropout(0.5))
dense_net_model.add(Dense(128, activation='relu',kernel_regularizer=regularizers.l2(0.001)))
dense_net_model.add(Dropout(0.5))
dense_net_model.add(Dense(2, activation='sigmoid'))
for layer in denset_net_pretrained_model.layers[:]:
    layer.trainable = False

dense_net_model.summary()

dense_net_model.compile(optimizer=Adam(learning_rate=0.001),loss='binary_crossentropy',metrics=["accuracy","AUC","Precision","Recall"])

history_dense_net_model = dense_net_model.fit(train_generator, validation_data=train_generator, epochs=3)

plt.figure(1, figsize = (12,6))

plt.subplot(221)
plt.plot(history_dense_net_model.history['accuracy'])
plt.plot(history_dense_net_model.history['val_accuracy'])
plt.title('model accuracy')
plt.ylabel('accuracy')
plt.xlabel('epoch')
plt.legend(['train', 'valid'])

plt.subplot(222)
plt.plot(history_dense_net_model.history['loss'])
plt.plot(history_dense_net_model.history['val_loss'])
plt.title('model loss')
plt.ylabel('loss')
plt.xlabel('epoch')
plt.legend(['train', 'valid'])

plt.show()

test_generator.reset()

pred = dense_net_model.predict(test_generator, steps = len(test_generator), verbose = 2)

predicted_class_indices = np.argmax(pred, axis = 1)

base_dir= "../content/pediatric-pneumonia-chest-xray/Pediatric Chest X-ray Pneumonia/"
y_test = Target_Data_Seperation(base_dir, target_path=[("test/NORMAL/", 0,), ("test/PNEUMONIA/", 1,)])

print(plot_confusion_matrix(confusion_matrix(y_test, predicted_class_indices), figsize=(5,5)))
print(accuracy_score(y_test, predicted_class_indices))
print(classification_report(y_test, predicted_class_indices))
plt.show()

import pickle
pickle.dump(dense_net_model,open('dense_net_model.pkl','wb'))

import pickle

pickle.dump(vgg_model,open('vgg_model.pkl','wb'))

a=test_datagen.flow_from_directory(
    directory="../content/Public",
    target_size=(180,180),
    color_mode="rgb",
    batch_size=1,
    class_mode=None,
    shuffle=False,
    seed=42
)

model = pickle.load(open("../content/dense_net_model.pkl",'rb'))
b=model.predict(a)

predicted_class_indices=np.argmax(b,axis=1)

print(predicted_class_indices)